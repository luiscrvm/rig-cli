import fs from 'fs';
import path from 'path';
import chalk from 'chalk';
import ora from 'ora';

export class MonitoringGenerator {
  constructor(cloudManager, aiAssistant, logger, outputDir = null) {
    this.cloudManager = cloudManager;
    this.aiAssistant = aiAssistant;
    this.logger = logger;
    this.outputDir = outputDir || path.join(process.cwd(), 'monitoring');
  }

  async generateComplete(analysis, options) {
    const spinner = ora('Generating complete monitoring stack...').start();
    
    try {
      // Create output directory structure
      this.ensureDirectoryExists(this.outputDir);
      this.ensureDirectoryExists(path.join(this.outputDir, 'prometheus'));
      this.ensureDirectoryExists(path.join(this.outputDir, 'grafana'));
      this.ensureDirectoryExists(path.join(this.outputDir, 'alertmanager'));
      this.ensureDirectoryExists(path.join(this.outputDir, 'loki'));
      
      // Generate Prometheus configuration
      await this.generatePrometheus(analysis, options);
      
      // Generate Grafana dashboards
      await this.generateGrafana(analysis, options);
      
      // Generate AlertManager configuration
      await this.generateAlertManager(analysis, options);
      
      // Generate Loki configuration for logs
      await this.generateLoki(analysis, options);
      
      // Generate Docker Compose for the monitoring stack
      await this.generateMonitoringDockerCompose(analysis);
      
      // Generate Kubernetes manifests for monitoring
      await this.generateMonitoringK8s(analysis);
      
      // Generate README
      await this.generateMonitoringReadme(analysis);
      
      spinner.succeed('Complete monitoring stack generated successfully');
      
      console.log(chalk.green('\n✅ Generated monitoring stack:'));
      console.log(chalk.gray(`📁 ${this.outputDir}/`));
      console.log(chalk.gray('├── prometheus/'));
      console.log(chalk.gray('│   ├── prometheus.yml'));
      console.log(chalk.gray('│   └── alerts.yml'));
      console.log(chalk.gray('├── grafana/'));
      console.log(chalk.gray('│   ├── dashboards/'));
      console.log(chalk.gray('│   └── provisioning/'));
      console.log(chalk.gray('├── alertmanager/'));
      console.log(chalk.gray('│   └── alertmanager.yml'));
      console.log(chalk.gray('├── k8s/'));
      console.log(chalk.gray('│   └── monitoring-stack.yaml'));
      console.log(chalk.gray('├── docker-compose.monitoring.yml'));
      console.log(chalk.gray('└── README.md'));
      
    } catch (error) {
      spinner.fail('Monitoring stack generation failed');
      throw error;
    }
  }

  async generatePrometheus(analysis, options) {
    const prometheusDir = path.join(this.outputDir, 'prometheus');
    
    // Generate main Prometheus config
    const prometheusConfig = `# Prometheus Configuration
# Generated by Rig CLI

global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: '${analysis?.projectName || 'default'}'
    environment: 'production'

rule_files:
  - "alerts.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  # Prometheus itself
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Node Exporter for system metrics
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  # Application metrics
  - job_name: '${analysis?.projectName || 'app'}'
    static_configs:
      - targets: ['app:${this.getMetricsPort(analysis)}']
    metrics_path: '/metrics'
    scrape_interval: 30s

${this.generateApplicationSpecificScrapeConfigs(analysis)}

  # Kubernetes metrics (if using K8s)
  - job_name: 'kubernetes-apiservers'
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    relabel_configs:
    - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
      action: keep
      regex: default;kubernetes;https

  - job_name: 'kubernetes-nodes'
    kubernetes_sd_configs:
    - role: node
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
    - role: pod
    relabel_configs:
    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
      action: keep
      regex: true
    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
      action: replace
      target_label: __metrics_path__
      regex: (.+)
    - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
      action: replace
      regex: ([^:]+)(?::\\d+)?;(\\d+)
      replacement: \$1:\$2
      target_label: __address__`;

    fs.writeFileSync(path.join(prometheusDir, 'prometheus.yml'), prometheusConfig);

    // Generate alert rules
    const alertRules = this.generateAlertRules(analysis);
    fs.writeFileSync(path.join(prometheusDir, 'alerts.yml'), alertRules);
  }

  generateAlertRules(analysis) {
    return `# Prometheus Alert Rules
# Generated by Rig CLI

groups:
- name: ${analysis?.projectName || 'app'}.rules
  rules:
  # High error rate
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value }} errors per second"

  # High response time
  - alert: HighResponseTime
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High response time detected"
      description: "95th percentile response time is {{ $value }} seconds"

  # High memory usage
  - alert: HighMemoryUsage
    expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.8
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High memory usage"
      description: "Memory usage is {{ $value | humanizePercentage }}"

  # High CPU usage
  - alert: HighCPUUsage
    expr: 100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High CPU usage"
      description: "CPU usage is {{ $value }}%"

  # Application down
  - alert: ApplicationDown
    expr: up{job="${analysis?.projectName || 'app'}"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Application is down"
      description: "{{ $labels.instance }} has been down for more than 1 minute"

  # Database connection issues
  - alert: DatabaseConnectionHigh
    expr: database_connections_active / database_connections_max > 0.8
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "High database connection usage"
      description: "Database connection usage is {{ $value | humanizePercentage }}"

${this.generateLanguageSpecificAlerts(analysis)}`;
  }

  generateLanguageSpecificAlerts(analysis) {
    let alerts = '';
    
    if (analysis?.techStack?.includes('Node.js')) {
      alerts += `
  # Node.js specific alerts
  - alert: NodeJSEventLoopLag
    expr: nodejs_eventloop_lag_seconds > 0.1
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Node.js event loop lag is high"
      description: "Event loop lag is {{ $value }} seconds"

  - alert: NodeJSHeapUsage
    expr: nodejs_heap_size_used_bytes / nodejs_heap_size_total_bytes > 0.8
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Node.js heap usage is high"
      description: "Heap usage is {{ $value | humanizePercentage }}"`;
    }
    
    return alerts;
  }

  async generateGrafana(analysis, options) {
    const grafanaDir = path.join(this.outputDir, 'grafana');
    const dashboardsDir = path.join(grafanaDir, 'dashboards');
    const provisioningDir = path.join(grafanaDir, 'provisioning');
    
    this.ensureDirectoryExists(dashboardsDir);
    this.ensureDirectoryExists(path.join(provisioningDir, 'dashboards'));
    this.ensureDirectoryExists(path.join(provisioningDir, 'datasources'));

    // Generate datasource configuration
    const datasourceConfig = `# Grafana Datasources
# Generated by Rig CLI

apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true

  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100
    editable: true`;

    fs.writeFileSync(path.join(provisioningDir, 'datasources', 'datasources.yml'), datasourceConfig);

    // Generate dashboard provisioning
    const dashboardProvisioning = `# Grafana Dashboard Provisioning
# Generated by Rig CLI

apiVersion: 1

providers:
  - name: 'default'
    orgId: 1
    folder: ''
    type: file
    disableDeletion: false
    editable: true
    options:
      path: /etc/grafana/provisioning/dashboards`;

    fs.writeFileSync(path.join(provisioningDir, 'dashboards', 'dashboards.yml'), dashboardProvisioning);

    // Generate application dashboard
    await this.generateApplicationDashboard(dashboardsDir, analysis);
    
    // Generate infrastructure dashboard
    await this.generateInfrastructureDashboard(dashboardsDir, analysis);
  }

  async generateApplicationDashboard(dashboardsDir, analysis) {
    const dashboard = {
      'dashboard': {
        'id': null,
        'title': `${analysis?.projectName || 'Application'} Monitoring`,
        'tags': ['generated', 'rig-cli'],
        'timezone': 'browser',
        'panels': [
          {
            'id': 1,
            'title': 'Request Rate',
            'type': 'graph',
            'targets': [
              {
                'expr': `rate(http_requests_total{job="${analysis?.projectName || 'app'}"}[5m])`,
                'legendFormat': '{{method}} {{status}}'
              }
            ],
            'gridPos': { 'h': 8, 'w': 12, 'x': 0, 'y': 0 }
          },
          {
            'id': 2,
            'title': 'Response Time',
            'type': 'graph',
            'targets': [
              {
                'expr': `histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="${analysis?.projectName || 'app'}"}[5m]))`,
                'legendFormat': '95th percentile'
              },
              {
                'expr': `histogram_quantile(0.50, rate(http_request_duration_seconds_bucket{job="${analysis?.projectName || 'app'}"}[5m]))`,
                'legendFormat': '50th percentile'
              }
            ],
            'gridPos': { 'h': 8, 'w': 12, 'x': 12, 'y': 0 }
          },
          {
            'id': 3,
            'title': 'Error Rate',
            'type': 'singlestat',
            'targets': [
              {
                'expr': `rate(http_requests_total{job="${analysis?.projectName || 'app'}",status=~"5.."}[5m]) / rate(http_requests_total{job="${analysis?.projectName || 'app'}"}[5m])`,
                'legendFormat': 'Error Rate'
              }
            ],
            'gridPos': { 'h': 8, 'w': 6, 'x': 0, 'y': 8 }
          },
          {
            'id': 4,
            'title': 'Active Users',
            'type': 'singlestat',
            'targets': [
              {
                'expr': `active_users{job="${analysis?.projectName || 'app'}"}`,
                'legendFormat': 'Active Users'
              }
            ],
            'gridPos': { 'h': 8, 'w': 6, 'x': 6, 'y': 8 }
          }
        ],
        'time': { 'from': 'now-1h', 'to': 'now' },
        'refresh': '5s'
      }
    };

    fs.writeFileSync(
      path.join(dashboardsDir, 'application-dashboard.json'), 
      JSON.stringify(dashboard, null, 2)
    );
  }

  async generateInfrastructureDashboard(dashboardsDir, analysis) {
    const dashboard = {
      'dashboard': {
        'id': null,
        'title': 'Infrastructure Monitoring',
        'tags': ['infrastructure', 'generated', 'rig-cli'],
        'timezone': 'browser',
        'panels': [
          {
            'id': 1,
            'title': 'CPU Usage',
            'type': 'graph',
            'targets': [
              {
                'expr': '100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)',
                'legendFormat': '{{instance}}'
              }
            ],
            'gridPos': { 'h': 8, 'w': 12, 'x': 0, 'y': 0 }
          },
          {
            'id': 2,
            'title': 'Memory Usage',
            'type': 'graph',
            'targets': [
              {
                'expr': '(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100',
                'legendFormat': '{{instance}}'
              }
            ],
            'gridPos': { 'h': 8, 'w': 12, 'x': 12, 'y': 0 }
          },
          {
            'id': 3,
            'title': 'Disk Usage',
            'type': 'graph',
            'targets': [
              {
                'expr': '(node_filesystem_size_bytes - node_filesystem_avail_bytes) / node_filesystem_size_bytes * 100',
                'legendFormat': '{{instance}} {{mountpoint}}'
              }
            ],
            'gridPos': { 'h': 8, 'w': 24, 'x': 0, 'y': 8 }
          }
        ],
        'time': { 'from': 'now-1h', 'to': 'now' },
        'refresh': '30s'
      }
    };

    fs.writeFileSync(
      path.join(dashboardsDir, 'infrastructure-dashboard.json'), 
      JSON.stringify(dashboard, null, 2)
    );
  }

  async generateAlertManager(analysis, options) {
    const alertmanagerDir = path.join(this.outputDir, 'alertmanager');
    
    const alertmanagerConfig = `# AlertManager Configuration
# Generated by Rig CLI

global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@${analysis?.projectName || 'example.com'}'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'
  routes:
  - match:
      severity: critical
    receiver: critical-alerts
  - match:
      severity: warning
    receiver: warning-alerts

receivers:
- name: 'web.hook'
  webhook_configs:
  - url: 'http://localhost:5001/'

- name: 'critical-alerts'
  email_configs:
  - to: 'admin@${analysis?.projectName || 'example.com'}'
    subject: 'CRITICAL: {{ .GroupLabels.alertname }}'
    body: |
      {{ range .Alerts }}
      Alert: {{ .Annotations.summary }}
      Description: {{ .Annotations.description }}
      {{ end }}
  slack_configs:
  - api_url: 'YOUR_SLACK_WEBHOOK_URL'
    channel: '#alerts'
    title: 'CRITICAL Alert'
    text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

- name: 'warning-alerts'
  email_configs:
  - to: 'team@${analysis?.projectName || 'example.com'}'
    subject: 'WARNING: {{ .GroupLabels.alertname }}'
    body: |
      {{ range .Alerts }}
      Alert: {{ .Annotations.summary }}
      Description: {{ .Annotations.description }}
      {{ end }}

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'dev', 'instance']`;

    fs.writeFileSync(path.join(alertmanagerDir, 'alertmanager.yml'), alertmanagerConfig);
  }

  async generateLoki(analysis, options) {
    const lokiDir = path.join(this.outputDir, 'loki');
    
    const lokiConfig = `# Loki Configuration
# Generated by Rig CLI

auth_enabled: false

server:
  http_listen_port: 3100
  grpc_listen_port: 9096

common:
  path_prefix: /loki
  storage:
    filesystem:
      chunks_directory: /loki/chunks
      rules_directory: /loki/rules
  replication_factor: 1
  ring:
    instance_addr: 127.0.0.1
    kvstore:
      store: inmemory

query_range:
  results_cache:
    cache:
      embedded_cache:
        enabled: true
        max_size_mb: 100

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 24h

ruler:
  alertmanager_url: http://localhost:9093

analytics:
  reporting_enabled: false`;

    fs.writeFileSync(path.join(lokiDir, 'loki.yml'), lokiConfig);
  }

  async generateMonitoringDockerCompose(analysis) {
    const dockerCompose = `# Monitoring Stack Docker Compose
# Generated by Rig CLI

version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    networks:
      - monitoring

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager:/etc/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
    restart: unless-stopped
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=grafana
      - GF_USERS_ALLOW_SIGN_UP=false
    restart: unless-stopped
    networks:
      - monitoring

  loki:
    image: grafana/loki:latest
    container_name: loki
    ports:
      - "3100:3100"
    volumes:
      - ./loki:/etc/loki
      - loki_data:/loki
    command: -config.file=/etc/loki/loki.yml
    restart: unless-stopped
    networks:
      - monitoring

  promtail:
    image: grafana/promtail:latest
    container_name: promtail
    volumes:
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./promtail:/etc/promtail
    command: -config.file=/etc/promtail/promtail.yml
    restart: unless-stopped
    networks:
      - monitoring

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    restart: unless-stopped
    networks:
      - monitoring

volumes:
  prometheus_data:
  grafana_data:
  loki_data:

networks:
  monitoring:
    driver: bridge`;

    fs.writeFileSync(path.join(this.outputDir, 'docker-compose.monitoring.yml'), dockerCompose);
  }

  async generateMonitoringK8s(analysis) {
    const k8sDir = path.join(this.outputDir, 'k8s');
    this.ensureDirectoryExists(k8sDir);

    const k8sManifests = `# Monitoring Stack for Kubernetes
# Generated by Rig CLI

apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      containers:
      - name: prometheus
        image: prom/prometheus:latest
        ports:
        - containerPort: 9090
        volumeMounts:
        - name: config
          mountPath: /etc/prometheus
        - name: data
          mountPath: /prometheus
        args:
          - '--config.file=/etc/prometheus/prometheus.yml'
          - '--storage.tsdb.path=/prometheus'
          - '--storage.tsdb.retention.time=200h'
          - '--web.enable-lifecycle'
      volumes:
      - name: config
        configMap:
          name: prometheus-config
      - name: data
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: monitoring
spec:
  selector:
    app: prometheus
  ports:
    - protocol: TCP
      port: 9090
      targetPort: 9090
  type: NodePort
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
    scrape_configs:
    - job_name: 'prometheus'
      static_configs:
      - targets: ['localhost:9090']
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true`;

    fs.writeFileSync(path.join(k8sDir, 'monitoring-stack.yaml'), k8sManifests);
  }

  async generateMonitoringReadme(analysis) {
    const readme = `# Monitoring Stack

This monitoring configuration was generated by Rig CLI for ${this.getProjectName(analysis)}.

## Components

- **Prometheus**: Metrics collection and alerting
- **Grafana**: Visualization and dashboards  
- **AlertManager**: Alert routing and notification
- **Loki**: Log aggregation
- **Node Exporter**: System metrics
- **Promtail**: Log collection

## Quick Start

### Using Docker Compose

\`\`\`bash
# Start the monitoring stack
docker-compose -f docker-compose.monitoring.yml up -d

# View services
docker-compose -f docker-compose.monitoring.yml ps

# View logs
docker-compose -f docker-compose.monitoring.yml logs -f grafana
\`\`\`

### Using Kubernetes

\`\`\`bash
# Deploy monitoring stack
kubectl apply -f k8s/monitoring-stack.yaml

# Check pods
kubectl get pods -n monitoring

# Access services
kubectl port-forward -n monitoring svc/prometheus 9090:9090
kubectl port-forward -n monitoring svc/grafana 3000:3000
\`\`\`

## Access URLs

- **Grafana**: http://localhost:3000 (admin/grafana)
- **Prometheus**: http://localhost:9090
- **AlertManager**: http://localhost:9093

## Dashboards

### Application Dashboard
- Request rate and response times
- Error rates and status codes
- Active users and business metrics

### Infrastructure Dashboard  
- CPU, memory, and disk usage
- Network I/O and system load
- Container and pod metrics

## Alerts

### Critical Alerts
- Application down
- High error rate (>10%)
- Database connection issues

### Warning Alerts
- High response time (>500ms)
- High resource usage (>80%)
- Event loop lag (Node.js)

## Customization

### Adding Custom Metrics

1. **Application Metrics**:
   ${this.getMetricsInstrumentation(analysis)}

2. **Custom Dashboards**:
   - Add JSON files to \`grafana/dashboards/\`
   - Configure in \`grafana/provisioning/dashboards/\`

3. **Custom Alerts**:
   - Edit \`prometheus/alerts.yml\`
   - Configure notifications in \`alertmanager/alertmanager.yml\`

### Environment Configuration

Copy and customize:
\`\`\`bash
cp .env.monitoring.example .env.monitoring
\`\`\`

## Troubleshooting

### Common Issues

1. **Prometheus can't scrape metrics**:
   - Check if application exposes \`/metrics\` endpoint
   - Verify network connectivity between containers

2. **Grafana shows "No data"**:
   - Verify Prometheus datasource configuration
   - Check time range in dashboard queries

3. **Alerts not firing**:
   - Check alert expression syntax
   - Verify AlertManager webhook URLs

### Useful Commands

\`\`\`bash
# Check Prometheus targets
curl http://localhost:9090/api/v1/targets

# Test AlertManager config
docker exec alertmanager amtool config check

# View Grafana logs
docker logs grafana
\`\`\`

## Generated by Rig CLI

This monitoring configuration was automatically generated by Rig CLI.
- Run \`rig generate monitoring\` to regenerate
- Run \`rig security --scan\` to check for security issues
- Run \`rig cost --analyze\` to analyze monitoring costs
`;

    fs.writeFileSync(path.join(this.outputDir, 'README.md'), readme);
  }

  // Helper methods
  getMetricsPort(analysis) {
    return analysis?.techStack?.includes('Node.js') ? '3001' : '8080';
  }

  getMetricsInstrumentation(analysis) {
    if (analysis?.techStack?.includes('Node.js')) {
      return `\`\`\`javascript
const client = require('prom-client');

// Custom counter
const requestCounter = new client.Counter({
  name: 'http_requests_total',
  help: 'Total number of HTTP requests',
  labelNames: ['method', 'status']
});

// Custom histogram  
const responseTime = new client.Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests in seconds',
  buckets: [0.1, 0.5, 1, 2, 5]
});
\`\`\``;
    } else if (analysis?.techStack?.includes('Python')) {
      return `\`\`\`python
from prometheus_client import Counter, Histogram, start_http_server

# Custom counter
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'status'])

# Custom histogram
REQUEST_LATENCY = Histogram('http_request_duration_seconds', 'HTTP request latency')

# Start metrics server
start_http_server(8080)
\`\`\``;
    }
    return 'Configure metrics collection based on your application stack';
  }

  generateApplicationSpecificScrapeConfigs(analysis) {
    let configs = '';
    
    if (this.hasDatabase(analysis)) {
      configs += `
  # Database metrics
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']`;
    }
    
    if (analysis?.dependencies?.some(dep => dep.includes('redis'))) {
      configs += `
  # Redis metrics
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']`;
    }
    
    return configs;
  }

  hasDatabase(analysis) {
    return analysis?.dependencies?.some(dep => 
      dep.includes('postgres') || dep.includes('mysql') || dep.includes('mongodb')
    );
  }

  getProjectName(analysis) {
    // Prefer GCP project name if available
    if (analysis?.infrastructure?.projectName) {
      return analysis.infrastructure.projectName;
    }
    
    // Get from environment variable (GCP project)
    const gcpProject = process.env.GCP_PROJECT_ID;
    if (gcpProject) {
      return gcpProject;
    }
    
    // Try to get from package.json name, but avoid CLI tool names
    if (analysis?.projectName && 
        analysis.projectName !== 'devops-cli' && 
        analysis.projectName !== 'rig-cli') {
      return analysis.projectName;
    }
    
    // Fallback to current directory name only if it's not the CLI tool
    const dirName = path.basename(process.cwd());
    if (dirName !== 'devops-cli' && dirName !== 'rig-cli') {
      return dirName;
    }
    
    // Final fallback
    return 'my-app';
  }

  ensureDirectoryExists(dir) {
    if (!fs.existsSync(dir)) {
      fs.mkdirSync(dir, { recursive: true });
    }
  }
}